#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
    about: False # set to False or comment line if you want to remove the "how to use?" in the sidebar
    education: False # set to False if you want education in main section instead of in sidebar

    # Profile information
    name: TaeIL Oh
    tagline: Vision Researcher
    avatar: profile.jpg  #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below

    # Sidebar links
    email: ooodragon94@gmail.com
    phone: '+82 10 2394 6882'
    website: ooodragon94.github.io/resume
    linkedin: taeil-oh
    github: ooodragon94

    languages:
      - idiom: 한국어
        level: 원어민

      - idiom: English
        level: Professional

career-profile:
    title: Career Profile
    summary: |
      I studied master's program at <a href="https://https://gistvision.github.io//">GIST Computer Vision Lab</a>.\
      <a href="http://ppolon.github.io/">Jonghyun Choi</a> is my advisor.

education:
    - degree: High School Diploma
      university: <a href="https://www.graded.br/">Graded - The American School of São Paulo, Brasil</a>
      time: 2010.08 -2013.07
      details: |
        Graduated from Graded.

    - degree: BS in Electric Electronics Engineering
      university: <a href="https://neweng.cau.ac.kr/index.do">Chung-Ang University, Seoul</a> (GPA 3.94 / 4.50)
      time: 2014.03 - 2020.02
      details: |
        Graduated from Chung-Ang University, Faculty of Electrical and Electronic Engineering
        - Won a prize in a on campus <a href="https://codershigh.github.io/WebSite/#/">IOS class</a>.
        - Won an award in a on campus contest called <a href="http://ict.cau.ac.kr/20150610/sub05/sub05_01_list.php?cmd=view&idx=211">"Always On"</a>.
        - Got an award from <a href="https://xcorps.snu.ac.kr/about/xcorps">X-Corps</a> by using bluetooth beacon and LSTM to estimate the user's position.

    - degree: MS in Computer Science
      university: <a href="https://www.gist.ac.kr/en/main.html">Gwangju Institute of Science and Technology(GIST), Gwangju</a> (GPA 4.0/4.50)
      time: 2020.03 - 2022.02
      details: |
        Received master's degree from the Computer Vision Lab (prof. Jonghyun Choi), Gwangju Institute of Science and Technology.
        Experienced following research fields in lab:
          - Model Compression: Knowledge Distillation, Network Pruning, Binary Network, Network Architecture Search
          - Image Generation: Downstream task information disentanglement for privacy, Zero shot Image Generation for privacy.

experiences:
  - title: Machine Learning Intern
    time: 2018.11 - 2019.02
    company: <a href="https://neweng.cau.ac.kr/index.do">Chung-Ang University, Seoul</a>
    topic: Internship during winter break
    details: |
      Learned basic ML knowledge.

  - title: <a href="https://github.com/ooodragon94/usurf">Machine Learning Intern</a>
    time: 2019.7 - 2019.8
    company: <a href="https://www.unist.ac.kr/">Ulsan National Institute of Science and Technology(UNIST)</a>
    topic: Internship during summer break
    details: |
      Learned and implemented following:
       - Histogram Equalization
       - Canny Edge Detection 
       - GAN
       - DCGAN
       - Reflection Reduction

projects:
    - title: <a href="https://github.com/ooodragon94/network-compress/">Model Compression</a>
      time: 2020.03 - 2022.02
      company: <a href="https://www.keti.re.kr/eng/main/main.php">Korea Electronics Technology Institute(KETI)</a>
      topic: Image Recognition
      details: |
        Project on compression deep neural network to implement on a chip.
        - Contributed on Model compression algorithm; Knowledge Distillation, Pruning to compress Convolutional Neural Network(CNN).
        - Used TensorRT to optimize network inference speed on Jetson Nano.

    - title: Knowledge Distillation
      time: 2020.03 - 2020.04
      company: GIST
      topic: Image Recognition
      details: |
        Researched on logit distillation, also known as dark knowledge distillation.
        - Distillation with large teacher on a restricted resource.\
        Many try to overcome the large teacher memory for distillation by saving its inference results.\
        However, this will give deterministic results even with different transformation.\
        Researched on a learned network that will change the teacher logit regarding to the applied transformation.

    - title: Image generation for privacy with information disentanglement
      time: 2020.07 - 2020.09
      company: GIST
      topic: Privacy
      details: |
        Research on generating images with no privacy concern.
        - Deep learning needs data to learn.
        - This has critial privacy concern and must be solved.
        - For this, we researched on generating images only with downstream task related information.

    - title: Zero shot face image generation
      time: 2020.10 - 2020.11
      company: GIST
      topic: Privacy
      details: |
        Used <a href="https://arxiv.org/pdf/1912.08795.pdf">Dream to Distill</a> for zero shot face image generation.

    - title: Noise Removal with only noisy images
      time: 2020.12 - 2021.01
      company: GIST
      topic: Noise Removal
      details: |
        Given only training image, we can estimate real error with Stein's unbiased risk estimate(SURE).\
        Using SURE, we researched on denoising method only with noisy images.

    - title: Network Pruning
      time: 2021.02 - 2021.06
      company: GIST
      topic: Image Recognition
      details: |
        Researched on filter pruning which is a subfield of network pruning.
        - Researched on zero shot pruning, a pruning technique which estimates importance score without any data given.
        - Researched on index matching while filter pruning. After the advent of residual network, this field has not progressed.\
        However, it is one of the most important problem to solve.

    - title: Binary Network
      time: 2021.07 - current
      company: GIST
      topic: Image Recognition
      details: |
        Researched on Binary Network, an extreme case of quantization.
        - Researched on better performing binary network with removing high quantization errror inducing filters.
        - Researched on Binary Network Architecture Search with pruning.
        - Binary Network application (currently working on this, no specification allowed. Planning to submit to ECCV2022)

skills:
    title: Skills &amp; Proficiency
    toolset:
      - name: Python
        level: 80%
        details: |
          - No problem on implementing ideas.
          - Used this language while studying for master's degree.
      - name: PyTorch
        level: 80%
        details: |
          - No problem on implementing ideas.
          - Modified other author's code to compare the method on our method.
          - Experienced extensive hyperparameter searching with <a href="https://docs.ray.io/en/latest/using-ray-with-pytorch.html">Ray</a>
          - No problem on making custom class while inheriting its class.
          - Used this library while studying for master's degree.
      - name: C
        level: 30%
        details: |
          - Studied for 1 year at Bachelor.
          - Done various projects by coding Arduino in this language.
      - name: Java
        level: 30%
        details: |
          - Studied for half year at Bachelor.

publications:
  title: Publications
  intro: Published papers regarding to done projects.
  papers:
    - title: <a href="http://conference.kimst.or.kr/data/programbook-1111-1.pdf">시각 인식을 위한 네트워크 경량화 기법</a>
      authors: 오태일, 최종현
      conference: KIMST (한국군사과학기술학회), 2020
    - title: <a href="https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE10583063">단일 영상 기반 텍스쳐 보존 잡음제거</a>
      authors: 조연식, 오태일, 최종현
      conference: KSC (한국정보과학회), 2021


#interests:
#    - title: Vision and Language
#      details: |
#        현재 발을 담그고 있는 분야입니다. 그 동안 Natural Language Video Localization(NLVL)을 연구하며 얻은 경험을 더 활용하여 더 많은 분야로 뻗어나가고 싶습니다.
#        특히 NLVL 분야를 중점적으로 알고 있으나, 다른 관련 분야 (예: Video Captioning, Dense Captioning, Vision-Language Navigation 등)에도 일정 수준의 지식을 가지고 있습니다.
#        - Video and Language: NLVL, Video (Dense) Captioning, Vision-Language Navigation, Video and Language Transformer
#        - Image and Language: Image Captioning, Scene Graph
#    - title: Video Processing
#      details: |
#        Natural Language Video Localization(NLVL)을 연구하며 비디오 프로세싱에 관한 노하우를 쌓았습니다.
#        이를 활용하여 비디오 관련 분야에 대해서도 공부하고 싶습니다.
#        - Video Denosing
#        - Action Recognition
#    - title: Audio Synthesis
#      details: |
#        개인적으로 사용할 곳이 많고 컴퓨터 비전이나 NLP에 비해 비교적 발전의 여지가 많이 남아있다고 생각하는 분야입니다.
#        [PyTorch-MFCC](https://github.com/skaws2003/pytorch-mfcc)와 같은 라이브러리를 제작하고 Interspeech등의 학회를 꾸준히 모니터링 하며 시류에 뒤쳐지지 않도록 노력하고 있습니다.
#        - Singing Voice Synthesis
#        - Speech Separation
#        - Vision and Audio


footer: >
    Designed with <i class="fas fa-heart"></i> by <a href="http://themes.3rdwavemedia.com"target="_blank" rel="nofollow">Xiaoying Riley</a> <br>
    Template modified by <a href="https://github.com/skaws2003">skaws2003</a>
